{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 74 images for Balayong (C NBG) into 59 for training and 15 for validation.\n",
      "Split 90 images for Balayong (SL) into 72 for training and 18 for validation.\n",
      "Split 77 images for Bayabas (C NBG) into 61 for training and 16 for validation.\n",
      "Split 78 images for Bayabas (S NBG into 62 for training and 16 for validation.\n",
      "Split 89 images for Dao (C NBG) into 71 for training and 18 for validation.\n",
      "Split 91 images for Dao (S NBG) into 72 for training and 19 for validation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the directory containing the class folders\n",
    "base_dir = r\"C:\\Users\\Ven\\Desktop\\Leaflet Data 2023\\data exp\"\n",
    "output_dir = r\"C:\\Users\\Ven\\Desktop\\Leaflet-CNN-Sequential\\model\\data\\Dataset exp\"\n",
    "\n",
    "# Get the list of subdirectories (class names)\n",
    "class_names = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each class folder and perform train-test split\n",
    "for class_name in class_names:\n",
    "    og_data_dir = os.path.join(base_dir, class_name)\n",
    "\n",
    "    # Define the output directories for train and validation data\n",
    "    train_dir = os.path.join(output_dir, \"train\", class_name)\n",
    "    valid_dir = os.path.join(output_dir, \"valid\", class_name)\n",
    "\n",
    "    # Create the train and validation directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "    # List all the image files in the data directory\n",
    "    image_files = [f for f in os.listdir(og_data_dir) if f.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \"JPG\"))]\n",
    "\n",
    "    # Calculate the number of images for the train and validation sets\n",
    "    total_images = len(image_files)\n",
    "    train_ratio = 0.8\n",
    "    num_train = int(total_images * train_ratio)\n",
    "    num_valid = total_images - num_train\n",
    "\n",
    "    # Randomly shuffle the list of image files\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Copy the first 'num_train' images to the train directory\n",
    "    for i in range(num_train):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(train_dir, image_files[i])\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    # Copy the remaining images to the validation directory\n",
    "    for i in range(num_train, total_images):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(valid_dir, image_files[i])\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    print(f\"Split {total_images} images for {class_name} into {num_train} for training and {num_valid} for validation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split with Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200 images for Balayong into 160 for training and 40 for validation.\n",
      "Split 200 images for Bayabas into 160 for training and 40 for validation.\n",
      "Split 200 images for Betis into 160 for training and 40 for validation.\n",
      "Split 200 images for Dao into 160 for training and 40 for validation.\n",
      "Split 200 images for Dita into 160 for training and 40 for validation.\n",
      "Split 200 images for Guyabano into 160 for training and 40 for validation.\n",
      "Split 200 images for Ilang-Ilang into 160 for training and 40 for validation.\n",
      "Split 200 images for Ipil into 160 for training and 40 for validation.\n",
      "Split 200 images for Kalios into 160 for training and 40 for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ven\\anaconda3\\lib\\site-packages\\PIL\\Image.py:3176: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200 images for Kamagong into 160 for training and 40 for validation.\n",
      "Split 200 images for Mulawin into 160 for training and 40 for validation.\n",
      "Split 200 images for Narra into 160 for training and 40 for validation.\n",
      "Split 200 images for Sintores into 160 for training and 40 for validation.\n",
      "Split 200 images for Yakal into 160 for training and 40 for validation.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the directory containing the class folders\n",
    "base_dir = r\"C:\\Users\\Ven\\Desktop\\CashCF Data\"\n",
    "output_dir = r\"C:\\Users\\Ven\\Desktop\\Cash-Counterfeat\\model\\data\"\n",
    "\n",
    "# Get the list of subdirectories (class names)\n",
    "class_names = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the size to which you want to resize the images\n",
    "target_size = (400, 300)\n",
    "\n",
    "# Iterate through each class folder and perform train-test split\n",
    "for class_name in class_names:\n",
    "    og_data_dir = os.path.join(base_dir, class_name)\n",
    "\n",
    "    # Define the output directories for train and validation data\n",
    "    train_dir = os.path.join(output_dir, \"train\", class_name)\n",
    "    valid_dir = os.path.join(output_dir, \"valid\", class_name)\n",
    "\n",
    "    # Create the train and validation directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "    # List all the image files in the data directory\n",
    "    image_files = [f for f in os.listdir(og_data_dir) if f.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \"JPG\"))]\n",
    "\n",
    "    # Calculate the number of images for the train and validation sets\n",
    "    total_images = len(image_files)\n",
    "    train_ratio = 0.80\n",
    "    num_train = int(total_images * train_ratio)\n",
    "    num_valid = total_images - num_train\n",
    "\n",
    "    # Randomly shuffle the list of image files\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Copy and resize the first 'num_train' images to the train directory\n",
    "    for i in range(num_train):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(train_dir, image_files[i])\n",
    "        with Image.open(src) as img:\n",
    "            # Check and apply EXIF orientation\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    break\n",
    "            try:\n",
    "                exif = dict(img._getexif().items())\n",
    "                if exif[orientation] == 3:\n",
    "                    img = img.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6:\n",
    "                    img = img.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8:\n",
    "                    img = img.rotate(90, expand=True)\n",
    "            except (AttributeError, KeyError, IndexError):\n",
    "                # No EXIF orientation or another issue\n",
    "                pass\n",
    "\n",
    "            img = img.resize(target_size)\n",
    "            img.save(dst)\n",
    "\n",
    "    # Copy and resize the remaining images to the validation directory\n",
    "    for i in range(num_train, total_images):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(valid_dir, image_files[i])\n",
    "        with Image.open(src) as img:\n",
    "            # Check and apply EXIF orientation\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    break\n",
    "            try:\n",
    "                exif = dict(img._getexif().items())\n",
    "                if exif[orientation] == 3:\n",
    "                    img = img.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6:\n",
    "                    img = img.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8:\n",
    "                    img = img.rotate(90, expand=True)\n",
    "            except (AttributeError, KeyError, IndexError):\n",
    "                # No EXIF orientation or another issue\n",
    "                pass\n",
    "\n",
    "            img = img.resize(target_size)\n",
    "            img.save(dst)\n",
    "\n",
    "    print(f\"Split {total_images} images for {class_name} into {num_train} for training and {num_valid} for validation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split with Resize (Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 200 images for Balayong into 160 for training and 40 for validation.\n",
      "Split 200 images for Bayabas into 160 for training and 40 for validation.\n",
      "Split 200 images for Betis into 160 for training and 40 for validation.\n",
      "Split 200 images for Dao into 160 for training and 40 for validation.\n",
      "Split 200 images for Dita into 160 for training and 40 for validation.\n",
      "Split 200 images for Guyabano into 160 for training and 40 for validation.\n",
      "Split 200 images for Ilang-Ilang into 160 for training and 40 for validation.\n",
      "Split 200 images for Ipil into 160 for training and 40 for validation.\n",
      "Split 200 images for Kalios into 160 for training and 40 for validation.\n",
      "Split 200 images for Kamagong into 160 for training and 40 for validation.\n",
      "Split 200 images for Mulawin into 160 for training and 40 for validation.\n",
      "Split 200 images for Narra into 160 for training and 40 for validation.\n",
      "Split 200 images for Sintores into 160 for training and 40 for validation.\n",
      "Split 200 images for Yakal into 160 for training and 40 for validation.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the directory containing the class folders\n",
    "base_dir = r\"C:\\Users\\Ven\\Desktop\\Leaflet Data 2023\\data exp\"\n",
    "output_dir = r\"C:\\Users\\Ven\\Desktop\\Leaflet-CNN-Sequential\\model\\data\\Dataset tl(14 classes 224 x 224)\"\n",
    "\n",
    "# Get the list of subdirectories (class names)\n",
    "class_names = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the size to which you want to resize the images\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Iterate through each class folder and perform train-test split\n",
    "for class_name in class_names:\n",
    "    og_data_dir = os.path.join(base_dir, class_name)\n",
    "\n",
    "    # Define the output directories for train and validation data\n",
    "    train_dir = os.path.join(output_dir, \"train\", class_name)\n",
    "    valid_dir = os.path.join(output_dir, \"valid\", class_name)\n",
    "\n",
    "    # Create the train and validation directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "    # List all the image files in the data directory\n",
    "    image_files = [f for f in os.listdir(og_data_dir) if f.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \"JPG\"))]\n",
    "\n",
    "    # Calculate the number of images for the train and validation sets\n",
    "    total_images = len(image_files)\n",
    "    train_ratio = 0.80\n",
    "    num_train = int(total_images * train_ratio)\n",
    "    num_valid = total_images - num_train\n",
    "\n",
    "    # Randomly shuffle the list of image files\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Copy and resize the first 'num_train' images to the train directory\n",
    "    for i in range(num_train):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(train_dir, image_files[i])\n",
    "        with Image.open(src) as img:\n",
    "            # Check and apply EXIF orientation\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    break\n",
    "            try:\n",
    "                exif = dict(img._getexif().items())\n",
    "                if exif[orientation] == 3:\n",
    "                    img = img.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6:\n",
    "                    img = img.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8:\n",
    "                    img = img.rotate(90, expand=True)\n",
    "            except (AttributeError, KeyError, IndexError):\n",
    "                # No EXIF orientation or another issue\n",
    "                pass\n",
    "\n",
    "            img = img.resize(target_size)\n",
    "            img.save(dst)\n",
    "\n",
    "    # Copy and resize the remaining images to the validation directory\n",
    "    for i in range(num_train, total_images):\n",
    "        src = os.path.join(og_data_dir, image_files[i])\n",
    "        dst = os.path.join(valid_dir, image_files[i])\n",
    "        with Image.open(src) as img:\n",
    "            # Check and apply EXIF orientation\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    break\n",
    "            try:\n",
    "                exif = dict(img._getexif().items())\n",
    "                if exif[orientation] == 3:\n",
    "                    img = img.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6:\n",
    "                    img = img.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8:\n",
    "                    img = img.rotate(90, expand=True)\n",
    "            except (AttributeError, KeyError, IndexError):\n",
    "                # No EXIF orientation or another issue\n",
    "                pass\n",
    "\n",
    "            img = img.resize(target_size)\n",
    "            img.save(dst)\n",
    "\n",
    "    print(f\"Split {total_images} images for {class_name} into {num_train} for training and {num_valid} for validation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
